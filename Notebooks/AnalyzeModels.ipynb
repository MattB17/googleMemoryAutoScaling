{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352c7664",
   "metadata": {},
   "source": [
    "# Analyze Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from MemoryAutoScaling import analysis, plotting\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d6a15",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0917b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_params_bar_plot(params, counts, model_name):\n",
    "    \"\"\"Renders a bar plot of `params` for `model_name` based on `counts`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params: np.array\n",
    "        A numpy array of the most common optimal parameters.\n",
    "    counts: np.array\n",
    "        A numpy array of integers representing counts for the parameters.\n",
    "    model_name: str\n",
    "        A string representing the name of the model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(params)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(n), counts)\n",
    "    plt.xticks(range(n), params)\n",
    "    plt.title(\"{} Model Most Common Optimal Parameter\".format(model_name.upper()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce264b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_prominent_params(model_results_df, top_params_count, model_name):\n",
    "    \"\"\"A plot of the `top_params_count` most prominent parameters in `model_results_df`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_results_df: pd.DataFrame\n",
    "        A pandas DataFrame containing model results.\n",
    "    top_params_count: int\n",
    "        An integer representing the number of parameters to be included in the plot.\n",
    "        The `top_params_count` most prominent parameters of `model_results_df` are plotted.\n",
    "    model_name: str\n",
    "        A string representing the name of the model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    params_data = model_results_df.groupby('params_{}'.format(model_name))['id'].count()\n",
    "    params_data = params_data.sort_values(ascending=False)\n",
    "    if len(params_data) > 5:\n",
    "        params_data = params_data[:5]\n",
    "    render_params_bar_plot(params_data.index, params_data.values, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb383ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_result_cdfs(model_results_df, model_name):\n",
    "    \"\"\"Builds CDFs of model result statistics for `model_name` from `model_results_df`.\n",
    "    \n",
    "    The CDFs are built for each model result statistic across all the traces modeled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_results_df: pd.DataFrame\n",
    "        A pandas DataFrame containing the model results for all traces.\n",
    "    model_name: str\n",
    "        A string representing the name of the model fit to the traces.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    colors = [\"blue\", \"black\", \"green\", \"red\"]\n",
    "    col_lst = [\"test_mase\", \"under_mase\", \"prop_under_preds\", \"max_under_pred\"]\n",
    "    for idx in range(len(colors)):\n",
    "        col_name = \"{0}_{1}\".format(col_lst[idx], model_name)\n",
    "        data_vals = model_results_df[col_name].values\n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        plotting.plot_cumulative_distribution_function(\n",
    "            data_vals, axes[row, col], \" \".join(col_name.title().split(\"_\")), colors[idx], \"CDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results(data_dir, top_params_count, model_name):\n",
    "    \"\"\"Retrieves the model results for `model_name` from `data_dir`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: str\n",
    "        A string representing the directory containing the model results.\n",
    "    top_params_count: int\n",
    "        An integer representing the number of parameters to be included in the plot.\n",
    "        The `top_params_count` most prominent parameters of `model_results_df` are plotted.\n",
    "    model_name: str\n",
    "        A string representing the name of the model for which results are retrieved.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A pandas DataFrame containing the model results.\n",
    "    \n",
    "    \"\"\"\n",
    "    model_df = pd.read_csv(os.path.join(data_dir, \"{}_results.csv\".format(model_name)))\n",
    "    print(model_df.describe())\n",
    "    plot_most_prominent_params(model_df, top_params_count, model_name)\n",
    "    build_model_result_cdfs(model_df, model_name)\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63802be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdfs_across_models(results_dfs, cdf_col):\n",
    "    \"\"\"Plots the CDFs of `cdf_col` across the models of `results_dfs`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dfs: dict\n",
    "        A dictionary of model results. The keys are strings representing the\n",
    "        name of the model. The corresponding value is a pandas DataFrame\n",
    "        recording results for the model across all traces.\n",
    "    cdf_col: str\n",
    "        A string representing the name of the variable for which the CDFs are\n",
    "        generated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for model_name in results_dfs.keys():\n",
    "        dist_vals = results_dfs[model_name][\"{0}_{1}\".format(cdf_col, model_name)].values\n",
    "        x, y = plotting.get_cdf_values(dist_vals)\n",
    "        plt.plot(x, y, label=model_name.upper())\n",
    "    plt.title(\"CDFs of {} Across Models\".format(\" \".join(cdf_col.title().split(\"_\"))))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4540176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_cdfs_across_models(results_dfs):\n",
    "    \"\"\"Plots all of the model result CDFs across the models of `results_dfs`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dfs: dict\n",
    "        A dictionary of model results. The keys are strings representing the\n",
    "        name of the model. The corresponding value is a pandas DataFrame\n",
    "        recording results for the model across all traces.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    cdf_col_lst = [\"test_mase\", \"under_mase\", \"prop_under_preds\", \"max_under_pred\"]\n",
    "    for cdf_col in cdf_col_lst:\n",
    "        plot_cdfs_across_models(results_dfs, cdf_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_best_model_bar_plot(model_names, counts):\n",
    "    \"\"\"Renders a bar plot of the `counts` data for `model_names`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_names: np.array\n",
    "        A numpy array of strings representing the names of the best models.\n",
    "    counts: np.array\n",
    "        A numpy array of integers representing the counts for each model of\n",
    "        `model_names` of traces for which that model performs best.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(model_names)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(n), counts)\n",
    "    plt.xticks(range(n), model_names)\n",
    "    plt.title(\"Counts of Best Model Types\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_of_best_model_types(best_models_df):\n",
    "    \"\"\"Plots the counts of best model types from `best_models_df`.\n",
    "    \n",
    "    A bar plot is rendered which counts the model of each type in\n",
    "    `best_models_df`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    best_models_df: pd.DataFrame\n",
    "        A pandas DataFrame containing the results for the best model for each\n",
    "        trace. There is a row for each trace specifying the trace id, model name,\n",
    "        model parameters, and model results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    counts_data = best_models_df.groupby('model')['id'].count()\n",
    "    counts_data = counts_data.sort_values(ascending=False)\n",
    "    render_best_model_bar_plot(counts_data.index, counts_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_best_model_results_for_all_traces(data_dir):\n",
    "    \"\"\"Displays a summary of the best model results found in `data_dir`.\n",
    "    \n",
    "    A pandas DataFrame of the best model results is loaded from `data_dir`. For\n",
    "    this dataframe, summary statistics are printed. Then a bar plot is created\n",
    "    which counts the number of traces for which each model outperforms all other\n",
    "    models. Lastly, a plot of 4 CDFs summarizing the 4 model evaluation parameters\n",
    "    is plotted across all traces.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: str\n",
    "        A string representing the directory from which the best model results\n",
    "        are loaded.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A pandas DataFrame of the best model results for each trace.\n",
    "    \n",
    "    \"\"\"\n",
    "    best_model_df = pd.read_csv(os.path.join(data_dir, \"best_model_results.csv\"))\n",
    "    print(best_model_df.describe())\n",
    "    plot_counts_of_best_model_types(best_model_df)\n",
    "    build_model_result_cdfs(best_model_df, \"best\")\n",
    "    return best_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06c08b",
   "metadata": {},
   "source": [
    "### Maximum Memory Usage - 3 Period Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d815356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_mem_3_dir = \"/Users/mattb/Desktop/Courses/MemoryAutoScaling/output_data/max_mem_3\"\n",
    "model_results_dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_dfs['ma'] = get_model_results(max_mem_3_dir, 5, \"ma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd521c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_results_dfs['es'] = get_model_results(max_mem_3_dir, 5, \"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21baa36f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_results_dfs['reg'] = get_model_results(max_mem_3_dir, 5, \"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c571b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_results_dfs['svm'] = get_model_results(max_mem_3_dir, 5, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad49fca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_results_dfs['xgb'] = get_model_results(max_mem_3_dir, 5, \"xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e57074",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_results_dfs['arima'] = get_model_results(max_mem_3_dir, 5, \"arima\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b994c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cdfs_across_models(model_results_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.output_best_model_results_from_model_results_dfs(model_results_dfs, max_mem_3_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(model_results_dfs.keys()) + ['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_dfs['best'] = display_best_model_results_for_all_traces(max_mem_3_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test MASE\")\n",
    "analysis.get_percentiles_df_for_model_results(model_results_dfs, model_names, \"test_mase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc145734",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Under Predictions MASE\")\n",
    "analysis.get_percentiles_df_for_model_results(model_results_dfs, model_names, \"under_mase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Proportion of Under Predictions\")\n",
    "analysis.get_percentiles_df_for_model_results(model_results_dfs, model_names, \"prop_under_preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum Magnitude of Relative Under Predictions\")\n",
    "analysis.get_percentiles_df_for_model_results(model_results_dfs, model_names, \"max_under_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84466552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
